{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.linear_model as lm\n",
    "from scipy.io import loadmat\n",
    "from sklearn import model_selection\n",
    "from dtuimldmtools import rlr_validate\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two-level cross validation linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from sklearn\n",
    "X,y = load_diabetes(return_X_y=True, as_frame=True, scaled=False)\n",
    "\n",
    "# Convert to pandas dataframe\n",
    "X = pd.DataFrame(X)\n",
    "y = pd.DataFrame(y)\n",
    "\n",
    "# # Standardize data\n",
    "X = (X - X.mean()) / X.std()\n",
    "y = (y - y.mean()) / y.std()\n",
    "\n",
    "# Rename columns\n",
    "X.rename(columns={'s1':'tc', 's2': 'ldl', 's3': 'hdl', 's4': 'tch', 's5': 'ltg', 's6': 'glu'}, inplace=True)\n",
    "\n",
    "# Add Offset\n",
    "X['Offset'] = 1\n",
    "# Move offset to first position\n",
    "cols = X.columns.tolist()\n",
    "cols = cols[-1:] + cols[:-1]\n",
    "X = X[cols]\n",
    "\n",
    "# Number of samples and features: N = samples, M = features\n",
    "N, M = X.shape\n",
    "\n",
    "# attribute names\n",
    "attributeNames = X.columns\n",
    "\n",
    "# Convert pandas dataframe to numpy array\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Crossvalidation\n",
    "# Create crossvalidation partition for evaluation\n",
    "K = 10\n",
    "CV = model_selection.KFold(K, shuffle=True)\n",
    "# Values of lambda\n",
    "lambdas = np.power(10.0, range(-10, 11))\n",
    "\n",
    "\n",
    "Error_train = np.empty((K, 1))\n",
    "Error_test = np.empty((K, 1))\n",
    "Error_train_rlr = np.empty((K, 1))\n",
    "Error_test_rlr = np.empty((K, 1))\n",
    "Error_train_nofeatures = np.empty((K, 1))\n",
    "Error_test_nofeatures = np.empty((K, 1))\n",
    "w_rlr = np.empty((M, K))\n",
    "mu = np.empty((K, M - 1))\n",
    "sigma = np.empty((K, M - 1))\n",
    "w_noreg = np.empty((M, K))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 19\u001b[0m\n\u001b[0;32m      8\u001b[0m internal_cross_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m in_train,validation_set \u001b[38;5;129;01min\u001b[39;00m CV\u001b[38;5;241m.\u001b[39msplit(X_train,y_train):\n\u001b[0;32m     13\u001b[0m     (\n\u001b[0;32m     14\u001b[0m         opt_val_err,\n\u001b[0;32m     15\u001b[0m         opt_lambda,\n\u001b[0;32m     16\u001b[0m         mean_w_vs_lambda,\n\u001b[0;32m     17\u001b[0m         train_err_vs_lambda,\n\u001b[0;32m     18\u001b[0m         test_err_vs_lambda,\n\u001b[1;32m---> 19\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mrlr_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambdas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minternal_cross_validation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Standardize outer fold based on training set, and save the mean and standard\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# deviations since they're part of the model (they would be needed for\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# making new predictions) - for brevity we won't always store these in the scripts\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     mu[k, :] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(in_train[:, \u001b[38;5;241m1\u001b[39m:], \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\canic\\anaconda3\\envs\\mldm\\Lib\\site-packages\\dtuimldmtools\\crossvalidation\\implementations.py:122\u001b[0m, in \u001b[0;36mrlr_validate\u001b[1;34m(X, y, lambdas, cvf)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validate regularized linear regression model using 'cvf'-fold cross validation.\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;124;03mFind the optimal lambda (minimizing validation error) from 'lambdas' list.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03mThe loss function computed as mean squared error on validation set (MSE).\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;124;03mtest_err_vs_lambda  test error as function of lambda (vector)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    121\u001b[0m CV \u001b[38;5;241m=\u001b[39m model_selection\u001b[38;5;241m.\u001b[39mKFold(cvf, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 122\u001b[0m M \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    123\u001b[0m w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((M, cvf, \u001b[38;5;28mlen\u001b[39m(lambdas)))\n\u001b[0;32m    124\u001b[0m train_error \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((cvf, \u001b[38;5;28mlen\u001b[39m(lambdas)))\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "#Outer layer:\n",
    "for train_index, test_index in CV.split(X, y):\n",
    "     # extract training and test set for current CV fold\n",
    "    X_train = X[train_index]\n",
    "    y_train = y[train_index]\n",
    "    X_test = X[test_index]\n",
    "    y_test = y[test_index]\n",
    "    internal_cross_validation = 10\n",
    "    \n",
    "    #Inner layer:\n",
    "    for in_train,validation_set in CV.split(X_train,y_train):\n",
    "\n",
    "        for i in range(20): #Amount of hyperpar combinations\n",
    "            \n",
    "            (\n",
    "                opt_val_err,\n",
    "                opt_lambda,\n",
    "                mean_w_vs_lambda,\n",
    "                train_err_vs_lambda,\n",
    "                test_err_vs_lambda,\n",
    "            ) = rlr_validate(in_train, validation_set, lambdas, internal_cross_validation)\n",
    "            \n",
    "            # Standardize outer fold based on training set, and save the mean and standard\n",
    "            # deviations since they're part of the model (they would be needed for\n",
    "            # making new predictions) - for brevity we won't always store these in the scripts\n",
    "            mu[k, :] = np.mean(in_train[:, 1:], 0)\n",
    "            sigma[k, :] = np.std(in_train[:, 1:], 0)\n",
    "\n",
    "            in_train[:, 1:] = (in_train[:, 1:] - mu[k, :]) / sigma[k, :]\n",
    "            X_test[:, 1:] = (X_test[:, 1:] - mu[k, :]) / sigma[k, :]\n",
    "\n",
    "            Xty = in_train.T @ y_train\n",
    "            XtX = in_train.T @ in_train\n",
    "\n",
    "            # Compute mean squared error without using the input data at all\n",
    "            Error_train_nofeatures[k] = (\n",
    "                np.square(y_train - y_train.mean()).sum(axis=0) / y_train.shape[0]\n",
    "            )\n",
    "            Error_test_nofeatures[k] = (\n",
    "                np.square(y_test - y_test.mean()).sum(axis=0) / y_test.shape[0]\n",
    "            )\n",
    "\n",
    "            # Estimate weights for the optimal value of lambda, on entire training set\n",
    "            lambdaI = opt_lambda * np.eye(M)\n",
    "            lambdaI[0, 0] = 0  # Do no regularize the bias term\n",
    "            w_rlr[:, k] = np.linalg.solve(XtX + lambdaI, Xty).squeeze()\n",
    "            # Compute mean squared error with regularization with optimal lambda\n",
    "            Error_train_rlr[k] = (\n",
    "                np.square(y_train - in_train @ w_rlr[:, k]).sum(axis=0) / y_train.shape[0]\n",
    "            )\n",
    "            Error_test_rlr[k] = (\n",
    "                np.square(y_test - X_test @ w_rlr[:, k]).sum(axis=0) / y_test.shape[0]\n",
    "            )\n",
    "\n",
    "            # Estimate weights for unregularized linear regression, on entire training set\n",
    "            w_noreg[:, k] = np.linalg.solve(XtX, Xty).squeeze()\n",
    "            # Compute mean squared error without regularization\n",
    "            Error_train[k] = (\n",
    "                np.square(y_train - in_train @ w_noreg[:, k]).sum(axis=0) / y_train.shape[0]\n",
    "            )\n",
    "            Error_test[k] = (\n",
    "                np.square(y_test - X_test @ w_noreg[:, k]).sum(axis=0) / y_test.shape[0]\n",
    "            )\n",
    "            # OR ALTERNATIVELY: you can use sklearn.linear_model module for linear regression:\n",
    "            # m = lm.LinearRegression().fit(X_train, y_train)\n",
    "            # Error_train[k] = np.square(y_train-m.predict(X_train)).sum()/y_train.shape[0]\n",
    "            # Error_test[k] = np.square(y_test-m.predict(X_test)).sum()/y_test.shape[0]\n",
    "\n",
    "            # Display the results for the last cross-validation fold\n",
    "            if k == K - 1:\n",
    "                plt.figure(k, figsize=(12, 8))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.semilogx(lambdas, mean_w_vs_lambda.T[:, 1:], \".-\")  # Don't plot the bias term\n",
    "                plt.xlabel(\"Regularization factor\")\n",
    "                plt.ylabel(\"Mean Coefficient Values\")\n",
    "                plt.grid()\n",
    "                # You can choose to display the legend, but it's omitted for a cleaner\n",
    "                # plot, since there are many attributes\n",
    "                # legend(attributeNames[1:], loc='best')\n",
    "\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.title(\"Optimal lambda: 1e{0}\".format(np.log10(opt_lambda)))\n",
    "                plt.loglog(\n",
    "                    lambdas, train_err_vs_lambda.T, \"b.-\", lambdas, test_err_vs_lambda.T, \"r.-\"\n",
    "                )\n",
    "                plt.xlabel(\"Regularization factor\")\n",
    "                plt.ylabel(\"Squared error (crossvalidation)\")\n",
    "                plt.legend([\"Train error\", \"Validation error\"])\n",
    "                plt.grid()\n",
    "\n",
    "            # To inspect the used indices, use these print statements\n",
    "            # print('Cross validation fold {0}/{1}:'.format(k+1,K))\n",
    "            # print('Train indices: {0}'.format(train_index))\n",
    "            # print('Test indices: {0}\\n'.format(test_index))\n",
    "\n",
    "        k += 1\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
